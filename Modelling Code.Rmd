---
title: "Research Code Final"
author: "Miguel Torres(2305614)"
date: "2023-09-27"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

### Libraries
```{r}
library(readxl)
library(mice)
library(sp) 
library(maptools) 
library(classInt) 
library(spdep)

library(tmap)
library(raster)

library(leaflet)
library(RColorBrewer)
library(dplyr)

library(INLA)
```

### Wastewater Data Import
```{r}
wwdat <- read_xlsx("New Data Recording Template_v2_CSIR 20.01.2023.xlsx",range = "A2:AA397", col_types = c("text","text","skip","date",rep("skip",10),"text","skip",rep("date",2),rep("text",2),rep("numeric",3),"text","skip","text","text"))
head(wwdat)
mydat <- as.data.frame(wwdat)
```

### Shape File
```{r}
SHP <- shapefile("SA_Wards2020.shp")
SHP$DistrictCo <- as.factor(SHP$DistrictCo)
SHP.ek <- SHP[SHP$DistrictCo=="EKU",]
```

### Data Cleaning
```{r}
#ensure "No" matches with 0, If "Yes" and 0, replace with NA
wwdat$`N1 gene copies/mL in raw sewage`[wwdat$`N1 gene`=="N"] <- 0
temp <- wwdat[wwdat$`N1 gene`=="Y",]
temp <- temp[complete.cases(temp$`N1 gene copies/mL in raw sewage`),]
obs <- temp$`N1 gene copies/mL in raw sewage`==0
ind <- as.numeric(rownames(temp[obs,]))

wwdat$`N1 gene copies/mL in raw sewage`[ind] <- NA

wwdat$`N2 gene copies/mL in raw sewage`[wwdat$`N2 gene`=="N"] <- 0
wwdat$`N2 gene copies/mL in raw sewage`[wwdat$`N2 gene copies/mL in raw sewage`=="quantified using N1 only"] <- NA
wwdat$`N2 gene copies/mL in raw sewage` <- as.numeric(wwdat$`N2 gene copies/mL in raw sewage`)
temp <- wwdat[wwdat$`N2 gene`=="Y",]
temp <- test[complete.cases(temp$`N2 gene copies/mL in raw sewage`),]
obs <- temp$`N2 gene copies/mL in raw sewage`==0
ind <- as.numeric(rownames(temp[obs,]))

wwdat$`N2 gene copies/mL in raw sewage`[ind] <- NA
#drop N1 and N2 yes column since it is corrected
wwdat <- wwdat[,-c(7,8)]

#remove WWTP suffix from Sites
for(i in 1:nrow(wwdat)) {
  wwdat$`Site name`[i] <- substring(wwdat$`Site name`[i],first=1,last=nchar(wwdat$`Site name`[i])-5)
}
#
wwdat$`Site name` <- as.factor(wwdat$`Site name`)
wwdat$`Site name`[wwdat$`Site name`=="Daveyton"] <- "A. Daveyton"
wwdat$`Site name`[wwdat$`Site name`=="Olifantsfontein"] <- "B. Olifantsfontein"
wwdat$`Site name` <- factor(wwdat$`Site name`,levels = c("A. Daveyton","B. Olifantsfontein",
                                                     "C. Vlakplaats","E. Herbert Bickley",
                                                     "D. Carl Grundlingh","F. Jan Smuts",
                                                     "G. JP Marais","H. Rynfield"))
colnames(wwdat) <- c("Site_Name","Type_of_Sample","Date","Lab_ID","DOC","DT","N1_gene_con.",
                     "N2_gene_con.","N1_sewage","N2_sewage","IC_con","Test_Res")

#Adding ward number value
w <- vector(length = nrow(wwdat),mode="numeric")
wwdat <- data.frame(wwdat, WardNumber = w)
tmp <- wwdat$Site_Name=="A. Daveyton"
wwdat$WardNumber[tmp] <- 67
tmp <- wwdat$Site_Name=="B. Olifantsfontein"
wwdat$WardNumber[tmp] <- 89
tmp <- wwdat$Site_Name=="C. Vlakplaats"
wwdat$WardNumber[tmp] <- 107
tmp <- wwdat$Site_Name=="D. Carl Grundlingh"
wwdat$WardNumber[tmp] <- 88
tmp <- wwdat$Site_Name=="E. Herbert Bickley"
wwdat$WardNumber[tmp] <- 88
tmp <- wwdat$Site_Name=="F. Jan Smuts"
wwdat$WardNumber[tmp] <- 97
tmp <- wwdat$Site_Name=="G. JP Marais"
wwdat$WardNumber[tmp] <- 73
tmp <- wwdat$Site_Name=="H. Rynfield"
wwdat$WardNumber[tmp] <- 27

colnames(wwdat) <- c("Site_Name","Type_of_Sample","Date","Lab_ID","DOC","DT","N1_gene_con.",
                     "N2_gene_con.","N1_sewage","N2_sewage","IC_con","Test_Res","WardNumber")

#used for extracting ids to subset ekurhuleni

```

### Other Data Imports
```{r}
ward.dat <- readRDS("Cases-By-Ward.rds")

ward.id <- as.character(ward.dat$WardID)
ward.id <- as.numeric(ward.id)
ind1 <- (ward.id > 79700000)
ind2 <- (ward.id < 79800000)

ind <- (ind1+ind2-1) #indices for ekurhulkeni wards
ind <- as.logical(ind)
ward.eku.ids <- ward.dat$WardID[ind]
templist <- vector("list",length(ward.dat[1,]))
templist[[1]] <- ward.dat$WardID[ind]
for(i in 2:length(ward.dat[1,])) {
  templist[[i]] <- ward.dat[ind,i]
}
#old case data
eku.cases <- list2DF(templist,nrow=112)
colnames(eku.cases) <- colnames(ward.dat)
#movement
move.pre <- readRDS("movement_pre.rds") #use this - BAU
move.eku <- move.pre[ind,ind]

#matrix is row stochastic (include external wards)
vals <- vector(mode="numeric",length=112)
for(i in 1:112) {
  vals[i] <- 1-sum(move.pre[which(ind)[i],ind])
}
move.eku <- cbind(move.eku,vals)

vals <- colMeans(move.pre[-ind,ind])
vals <- append(vals,sum(colMeans(move.pre[-ind,-ind])))
vals <- vals/sum(vals)

move.eku <- rbind(move.eku,vals)
colnames(move.eku) <- c(1:112,"Ext. Wards")
rownames(move.eku) <- c(1:112,"Ext. Wards")

#severity data
severity <- readRDS("Ward-Level-Severity-Adjustment.rds")
#Sevetiy for Ekurhuleni
ind1 <- severity$WardID>79700000
ind2 <- severity$WardID<79800000
ind <- (ind1+ind2-1)
ind <- as.logical(ind)
sev.eku <- severity[ind,]

#vulnerability data
vulnerable <- readRDS("Wards_withDat_withVuln_withInitial.rds")

# make the vulnerability data centre on 1 with a range of 0.4
vulnerable$Vulnerability <- (vulnerable$Vulnerability-min(vulnerable$Vulnerability))/(max(vulnerable$Vulnerability)-min(vulnerable$Vulnerability))  # normalise the data
vulnerable$Vulnerability <- vulnerable$Vulnerability*0.4 ### scale this to range between 0 and 0.4
vulnerable$Vulnerability <- scale(vulnerable$Vulnerability, scale = F)+1  ## center these data on zero then add 1 to centre on 1

#vulnerability for Ekurhuleni
temp <- as.numeric(as.character(vulnerable$WardID))
ind1 <- temp>79700000
ind2 <- temp<79800000
ind <- (ind1+ind2-1) #indices for ekurhulkeni wards
ind <- as.logical(ind)
vulnerable.eku <- vulnerable[ind,]

#hospital data
hosp.raw <- read_xlsx("HospitalCopy.xlsx")
hosp.wards <- read.csv("HospitalsInWards.csv")
hosp.data <- hosp.raw[,c("Facility","Admission Date","AdmissionReason")]
names(hosp.data) <- c("Facility","AdmissionDate","AdmissionReason")
#AdmissionReason is ignored for now since not all hospitals report reason
#it would not be reasonable to exlude entries for only some hospitals

#matching wards and hospitals
hosp.wards <- mutate(hosp.wards,wardNum = as.numeric(substring(hosp.wards$ward,first = 3))) # run once
#arrange(SHP.ek@data[,c("WardID","WardNo","Municipali")],WardNo) 

hosp.wards <- rename(hosp.wards,"Facility" = "X", "Coord1"="name","Coord2"="geometry") #run once
#arrange(hosp.wards,WardNo)
#Missing hospitals
hosp.wards <- hosp.wards %>% add_row(Facility = "Netcare Alberton Hospital", Coord1 = "c(28",Coord2 = "-25)",
                       ward="ZA7970094",wardNum=7970094)

hosp.wards <- hosp.wards %>% add_row(Facility = "Morehill Clinic Physical Rehab", Coord1 = "c(28",Coord2 = "-25)",
                       ward="ZA7970024",wardNum=7970024)

#Adding wards to hospitalisation data
hosp.final <- left_join(hosp.data,hosp.wards,by="Facility")
hosp.final <- hosp.final[,-(4:6)]
hosp.final$Facility <- as.factor(hosp.final$Facility)
#Removing NA wards
ind <- is.na(hosp.final$wardNum)
hosp.final <- hosp.final[-(1:nrow(hosp.final))[ind],]

#District level case data from GitHub
cases.dash <- read_xlsx("EkurhuleniCasesDashboard.xlsx")
cases.dash <- cases.dash[,c("date","Ekurhuleni	Cases","source")]
names(cases.dash) <- c("Date","Cases","Source")

#Ward populations
pop.wards <- read_xlsx("ZQryPopDens.xlsx")
ind <- pop.wards$WardID_2017 >= 7970000
pop.wards <- pop.wards[ind,]
ind <- pop.wards$WardID_2017 < 7980000
pop.wards <- as.vector(unlist(pop.wards[ind,3]))
totpop <- sum(pop.wards)
pop.wards <- pop.wards/totpop

#Exclusing wards outside Ekurhuleni
ind <- (hosp.final$wardNum > 7970000) + (hosp.final$wardNum < 7980000)
ind <- ind==2
hosp.final.eku <- hosp.final %>% slice(((1:nrow(hosp.final))[ind]))

#subsetting by date
start.date <- as.POSIXct("2021-09-20")
ind <- hosp.final.eku$AdmissionDate >= start.date
hosp.final.eku <- hosp.final.eku[ind,]
hosp.final.eku %>% group_by(wardNum) %>% count()

#Extracting per week
ind <- weekdays(hosp.final.eku$AdmissionDate)=="Tuesday"
dates <- sort(unique(hosp.final.eku$AdmissionDate[ind]))

#initialise empty data frame
hosp.props <- data.frame(matrix(nrow = 0,ncol=3))

for(i in 1:length(dates)) {
  ind <- hosp.final.eku$AdmissionDate <= dates[i]
  hosp.temp <- hosp.final.eku[ind,]
  hosp.temp <- hosp.temp %>% group_by(wardNum) %>% count() #add counts per ward
  hosp.temp$n <- hosp.temp$n/sum(hosp.temp$n) #convert to proportion
  date.temp <- rep(dates[i],nrow(hosp.temp))
  hosp.temp <- cbind(hosp.temp,Date = date.temp)
  #listT[[i-1]] <- hosp.temp
  hosp.props <- rbind(hosp.props,hosp.temp)
}
```

### Hospitalisation Disaggregation
```{r}
hosp.props <- hosp.props %>% rename("WardNo" = "wardNum") #rename (this should only be run once)
#hospital plot
#ind <- unique(hosp.props$WardNo)
#cols.hosp <- rep(0,112)
#cols.hosp[ind] <- 2
#plot(SHP.ek,col=cols.hosp)

#assumed grouping (domains)
h1 <- c(1:17,23:25,89:91,100,102,104)
h2 <- c(18:22,32:36,39,92:93)
h3 <- c(37:38,40:64,94:95,101,103,106:108)
h4 <- c(26:31,65:73,75,96:97,105,109,110) #moved 74 from here to h5
h5 <- c(74,76:88,98:99,111,112)

#plots of areas
cols.hosp <- rep(0,112)
brew <- brewer.pal(5,"Set2")
cols.hosp[h1] <- brew[1]
cols.hosp[h2] <- brew[2]
cols.hosp[h3] <- brew[3]
cols.hosp[h4] <- brew[4]
cols.hosp[h5] <- brew[5]

plot(SHP.ek,col=cols.hosp)
legend(x=27.8, y=-25.9, legend = c("Area 1", "Area 2","Area 3","Area 4","Area 5"),fill=brew,bty="n")

hosp.props$WardNo <- hosp.props$WardNo - 7970000 #correcting ward number

d <- vector() #date
prop <- vector() #proportion
wn <- vector() #ward number
dates <- as.POSIXct(unique(hosp.props$Date))
#for region 1 total hospital cases (repeated for each area)
for(i in 1:length(dates)) {
  subset <- hosp.props[hosp.props$Date==dates[i],]
  sum1 <- 0
  for(j in 1:nrow(subset)) {
    if(subset$WardNo[j] %in% h1) {
      sum1 <- sum1 + subset$n[j]
    }
  }
#for region 1 disaggregate using ward populations (repeated for each area)
  for(k in h1) {
    d <- append(d,dates[i])
    prop <- append(prop,sum1*pop.wards[k]/sum(pop.wards[h1]))
    wn <- append(wn,k)
  }
  
  sum5 <- 0
  for(j in 1:nrow(subset)) {
    if(subset$WardNo[j] %in% h5) {
      sum5 <- sum5 + subset$n[j]
    }
  }
  
  for(k in h5) {
    d <- append(d,dates[i])
    prop <- append(prop,sum5*pop.wards[k]/sum(pop.wards[h5]))
    wn <- append(wn,k)
  }
  
  sum2 <- 0
  for(j in 1:nrow(subset)) {
    if(subset$WardNo[j] %in% h2) {
      sum2 <- sum2 + subset$n[j]
    }
  }
  
  for(k in h2) {
    d <- append(d,dates[i])
    prop <- append(prop,sum2*pop.wards[k]/sum(pop.wards[h2]))
    wn <- append(wn,k)
  }
  
  sum3 <- 0
  for(j in 1:nrow(subset)) {
    if(subset$WardNo[j] %in% h3) {
      sum3 <- sum3 + subset$n[j]
    }
  }
  
  for(k in h3) {
    d <- append(d,dates[i])
    prop <- append(prop,sum3*pop.wards[k]/sum(pop.wards[h3]))
    wn <- append(wn,k)
  }
  
  sum4 <- 0
  for(j in 1:nrow(subset)) {
    if(subset$WardNo[j] %in% h4) {
      sum4 <- sum4 + subset$n[j]
    }
  }
  
  for(k in h4) {
    d <- append(d,dates[i])
    prop <- append(prop,sum4*pop.wards[k]/sum(pop.wards[h4]))
    wn <- append(wn,k)
  }
}
hosp.prox <- data.frame(WardNo = wn, Date = d, Proportion = prop)
```

### Wastewater drainage areas
```{r}
eku.drainage <- read_xlsx("Ekurhuleni_Metro_WWTP_Serviced_and_Unserviced_SP_MP_Attribute_table.xlsx")
eku.drainage <- eku.drainage[,c("SP_CODE","SP_NAME","WWTP","WWTP_2","MP_CODE","WWTP_CODE")]

#extract important vars
N1.wards <- wwdat[,c("N1_sewage","N2_sewage","WardNumber","Date")]
N1.wards <- N1.wards[N1.wards$Date >= as.POSIXct("2020-09-20"),]
for(i in 1:length(N1.wards)) {
  if((is.na(N1.wards$N1_sewage[i]) || N1.wards$N1_sewage[i]==0)) {
    N1.wards$N1_sewage[i] <- N1.wards$N2_sewage[i] #use N2 as a proxy
  }
}
#drop N2 now that it has been used
N1.wards <- N1.wards[,-2]
N1.wards <- na.omit(N1.wards) #omit remaining NA

# make cumulative sum for N1 gene
N1.wards <- N1.wards %>% group_by(WardNumber) %>% arrange(Date) %>% mutate(cum_sewage = cumsum(N1_sewage))
N1.wards <- N1.wards %>% rename("N1_cusum" = "cum_sewage")

N1.wards$Date[165] <- as.POSIXct("2022-03-01",tz="UCT") #Correcting Erroneous date
```

### Wastewater disaggregation
```{r}
indD <- c(65:72,75,109,110) #Daveyton (67)
indO <- c(1:14,89:91,100,102) #Olifantsfontein (89)
indV <- c(30:64,80:83,94:95,101,103,105:108) #Vlakplaats (107)
indHBCG <- c(88,98) # HB and CG (88)
indR <- c(24,27) # R(27)
indJP <- 73 # JP
indJS <- 97 # JS

#wards for missing areas
r1 <- c(25:26,96) #(TR)
r2 <- c(15:23,28,29,92:93,104) #(TL)
r3 <- c(74,76:79,111) #(BR)
r4 <- c(84:87,99,112) #(BL)
#for the missing areas we need to generate values for the drainage area(code below)
#then use that for weighted averages: we generate for each week 1 value for each region
#finally, disaggregate same as below

#replace ward 88 and 89 by weighted average of the 2
temp <- N1.wards[N1.wards$WardNumber==88,]
dates <- sort(unique(temp$Date))
w <- c(9.5,128) #polulations of WWTP
N1.wards <- N1.wards[-which(N1.wards$WardNumber==88),]

for(i in 1:length(dates)) {
  subset <- temp[temp$Date==dates[i],]
  if(nrow(subset)==2) {
    t1 <- w[1]/sum(w)*subset$N1_sewage[1]+w[2]/sum(w)*subset$N1_sewage[2]
    t2 <- w[1]/sum(w)*subset$N1_cusum[1]+w[2]/sum(w)*subset$N1_cusum[2]
  }
  else {
    t1 <- subset$N1_sewage[1]
    t2 <- subset$N1_cusum[1]
  }
  row.temp <- data.frame(N1_sewage=t1,WardNumber=88,Date=dates[i],N1_cusum=t2)
  temp <- rbind(temp,row.temp)
}

temp <- temp[-(1:105),]

N1.wards <- rbind(N1.wards,temp)

#copy data set
N1.temp <- N1.wards[-1]
N1.temp2 <- N1.temp
for(i in 1:nrow(N1.temp)) {
  #disaggregate based on region
  if(N1.temp$WardNumber[i] %in% indD) {
    cusum <- pop.wards[indD]/sum(pop.wards[indD])*N1.temp$N1_cusum[i]
    row.temp <- data.frame(WardNumber = indD,
                           Date = rep(N1.temp$Date[i],length(indD)),N1_cusum = cusum)
    N1.temp2 <- rbind(N1.temp2,row.temp)
  }
  if(N1.temp$WardNumber[i] %in% indO) {
    cusum <- pop.wards[indO]/sum(pop.wards[indO])*N1.temp$N1_cusum[i]
    row.temp <- data.frame(WardNumber = indO,
                           Date = rep(N1.temp$Date[i],length(indO)),N1_cusum = cusum)
    N1.temp2 <- rbind(N1.temp2,row.temp)
  }
  if(N1.temp$WardNumber[i] %in% indV) {
    cusum <- pop.wards[indV]/sum(pop.wards[indV])*N1.temp$N1_cusum[i]
    row.temp <- data.frame(WardNumber = indV,
                           Date = rep(N1.temp$Date[i],length(indV)),N1_cusum = cusum)
    N1.temp2 <- rbind(N1.temp2,row.temp)
  }
  if(N1.temp$WardNumber[i] %in% indHBCG) {
    cusum <- pop.wards[indHBCG]/sum(pop.wards[indHBCG])*N1.temp$N1_cusum[i]
    row.temp <- data.frame(WardNumber = indHBCG,
                           Date = rep(N1.temp$Date[i],length(indHBCG)),N1_cusum = cusum)
    N1.temp2 <- rbind(N1.temp2,row.temp)
  }
  if(N1.temp$WardNumber[i] %in% indR) {
    cusum <- pop.wards[indR]/sum(pop.wards[indR])*N1.temp$N1_cusum[i]
    row.temp <- data.frame(WardNumber = indR,
                           Date = rep(N1.temp$Date[i],length(indR)),N1_cusum = cusum)
    N1.temp2 <- rbind(N1.temp2,row.temp)
  }
  
}

N1.temp2 <- N1.temp2[-(1:nrow(N1.temp)),] #ensure to run this when rerunning
#get unique set of neighbours for 'missing' areas
neigh <- poly2nb(SHP.ek)
n1 <- vector()
n2 <- vector()
n3 <- vector()
n4 <- vector()
for(i in r1) {
 n1 <- append(n1,neigh[[i]])
}
for(i in r2) {
 n2 <- append(n2,neigh[[i]])
}
for(i in r3) {
 n3 <- append(n3,neigh[[i]])
}
for(i in r4) {
 n4 <- append(n4,neigh[[i]])
}
n1 <- unique(n1)
n2 <- unique(n2)
n3 <- unique(n3)
n4 <- unique(n4)

n1 <- setdiff(n1,r1)
n2 <- setdiff(n2,r2)
n3 <- setdiff(n3,r3)
n4 <- setdiff(n4,r4)

#ind <- weekdays(N1.wards$Date)=="Tuesday"
#dates <- N1.wards$Date[ind]
dates <- unique(N1.wards$Date)
dates <- as.POSIXct(dates)

#create cumulative sums for the 4 'missing' regions
cusum <- vector()
d <- vector()
wn <- vector()
for(i in 1:length(dates)) {
  ind <- N1.temp2$Date==dates[i]
  subset <- N1.temp2[ind,]
  
  ind <- subset$WardNumber %in% n1
  cusum <- append(cusum,mean(subset$N1_cusum[ind]))
  
  ind <- subset$WardNumber %in% n2
  cusum <- append(cusum,mean(subset$N1_cusum[ind]))
  
  ind <- subset$WardNumber %in% n3
  cusum <- append(cusum,mean(subset$N1_cusum[ind]))
  
  ind <- subset$WardNumber %in% n4
  cusum <- append(cusum,mean(subset$N1_cusum[ind]))
  
  d <- append(d,rep(dates[i],4))
  wn <- append(wn,c(25,15,74,84))
}
N1.missing.ave <- data.frame(WardNumber = wn, Date = d, N1_cusum = cusum)
N1.missing.ave[4,3] <- 0

for(i in 1:nrow(N1.missing.ave)) {
  if(is.na(N1.missing.ave$N1_cusum[i])) {
    N1.missing.ave$N1_cusum[i] <- N1.missing.ave$N1_cusum[i-4]
  }
}

#disaggregate for each region
N1.missing.temp <- N1.missing.ave
wn <- vector()
d <- vector()
cusum <- vector()
for(i in 1:(nrow(N1.missing.ave)/4)) {
  cusum <- append(cusum,pop.wards[r1]/sum(pop.wards[r1])*N1.missing.ave$N1_cusum[(i-1)*4+1])
  cusum <- append(cusum,pop.wards[r2]/sum(pop.wards[r2])*N1.missing.ave$N1_cusum[(i-1)*4+2])
  cusum <- append(cusum,pop.wards[r3]/sum(pop.wards[r3])*N1.missing.ave$N1_cusum[(i-1)*4+3])
  cusum <- append(cusum,pop.wards[r4]/sum(pop.wards[r4])*N1.missing.ave$N1_cusum[(i-1)*4+4])
  
  wn <- append(wn,c(r1,r2,r3,r4))
  d <- append(d,rep(N1.missing.ave$Date[(i-1)*4+1],29))
  
}
N1.missing.temp <- data.frame(WardNumber = wn, Date = d, N1_cusum = cusum)

N1.final <- rbind(N1.temp2,N1.missing.temp)

#Inserting Jan Smuts and GP Marais
N1.final <- rbind(N1.final,N1.wards[N1.wards$WardNumber==73,-1])
N1.final <- rbind(N1.final,N1.wards[N1.wards$WardNumber==97,-1])
```

### Case disaggregation
```{r}
cases.dash.2021 <- cases.dash[cases.dash$Date >= as.POSIXct("2021-09-20",tz="UTC"),] #start date
#cases.dash.2021 <- na.omit(cases.dash.2021)
ind <- weekdays(cases.dash.2021$Date)=="Tuesday"
cases.dash.2021 <- cases.dash.2021[ind,]

#interpolating cases
for(i in 1:nrow(cases.dash.2021)) {
  if(is.na(cases.dash.2021$Cases[i])) {
    j <- 1
    flag1 <- FALSE
    while(is.na(cases.dash.2021$Cases[i-j])) {
      j <- j+1
      if(i-j<1) {
        flag1 <- TRUE
        break
      }
    }
     k <- 1
     flag2 <- FALSE
    while(is.na(cases.dash.2021$Cases[i+k])) {
      k <- k+1
      if(i+k>nrow(cases.dash.2021)) {
        flag2 <-TRUE
        break
      }
    }
    if(!flag1 && !flag2) {
    cases.dash.2021$Cases[i] <- with(cases.dash.2021,(k*Cases[i-j]+j*Cases[i+k])/(j+k)) 
    #weighted average based on time apart
    }
    else {
      if(flag1 && flag2) {
        print("Error, all NA")
      }
     else {
       if(flag1) {
         cases.dash.2021$Cases[i] <- cases.dash.2021$Cases[i+k]
       }
       if(flag2) {
         cases.dash.2021$Cases[i] <- cases.dash.2021$Cases[i-j]
       }
     }
    }
  }
}

cases.dash.2021$Cases <- with(cases.dash.2021,Cases - min(Cases)) #cases adjusted to start at 0 

#copy of hospital data subsetted by date
hosp.prox.t <- hosp.prox[hosp.prox$Date<=as.POSIXct("2022-03-30"),] #max date of cases
cases <- vector(length=nrow(hosp.prox.t))
#hosp.prox$Date <- hosp.prox$Date -7200

#disaggregate district cases using hospital data
for(i in 1:nrow(hosp.prox.t)) {
  cases[i] <- hosp.prox.t$Proportion[i]*cases.dash.2021$Cases[ceiling(i/112)]
}
cases.final <- cbind(hosp.prox.t,cases)
```

### Final data combining and rearranging
```{r}
cases.final.test <- cases.final %>% arrange(Date,WardNo)
N1.final.test <- N1.final[N1.final$Date>=as.POSIXct("2021-09-20",tz="UTC"),] #start date
N1.final.test <- N1.final.test[N1.final.test$Date<=as.POSIXct("2022-03-30",tz="UTC"),]
N1.final.test <- N1.final.test %>% arrange(Date,WardNumber)

#interpolating wastewater data
nrow(cases.final) - nrow(N1.final.test)
d1 <- unique(cases.final$Date)
d2 <- unique(N1.final.test$Date)
#d1
#d2
# missing: 2021-09-28 2021-10-12 2021-10-26 2021-11-09 2021-11-23 2022-01-04
# changes: 2021-10-21 -> 2021-10-19 ; 2021-12-01 -> 2021-11-30
# 2021-12-08 -> 2021-12-07 ; 2021-12-15 -> 2021-12-14; 2022-01-26 -> 2022-01-25
# 2022-02-23 -> 2022-02-22

#Interpolating
dates <- c("2021-09-28","2021-10-12","2021-10-26","2021-11-09","2021-11-23")
for(i in 1:5){
subset1 <- N1.final.test[N1.final.test$Date==d2[i],]
subset2 <- N1.final.test[N1.final.test$Date==d2[i+1],]
temp <- data.frame(WardNumber = 1:112, Date = rep(as.POSIXct(dates[i],tz="UTC"),112),
                   N1_cusum =  0.5*(subset1$N1_cusum+subset2$N1_cusum))
N1.final.test <- rbind(N1.final.test,temp)
}

subset1 <- N1.final.test[N1.final.test$Date==d2[10],]
subset2 <- N1.final.test[N1.final.test$Date==d2[11],]

temp <- data.frame(WardNumber = 1:112, Date = rep(as.POSIXct("2022-01-04",tz="UTC"),112),
                   N1_cusum =  0.5*(subset1$N1_cusum+subset2$N1_cusum))

N1.final.test <- rbind(N1.final.test,temp)

N1.final.test <- N1.final.test %>% arrange(Date,WardNumber)

cases.final.test <- cases.final %>% arrange(Date,WardNo)
#adding cases
data.final <- cbind(N1.final.test,Cases = cases.final.test$cases)
#adding other covariates
data.final <- cbind(data.final,Vulnerability = rep(vulnerable.eku@data$Vulnerability,28))

move.eku <- as.matrix(move.eku)
move.eku.out <- 1-diag(move.eku[-113,-113])
data.final <- cbind(data.final,Movement = rep(move.eku.out,28))

#data can be used for modelling
data.final <- cbind(data.final,Severity = rep(sev.eku$critical,28))

#arranging
data.final <- data.final %>% arrange(Date,WardNumber)
```



### Spatial Autocorrelation Tests
```{r}
neigh <- poly2nb(vulnerable.eku)
listW <- nb2listw(neigh)
#lA <- lag.listw(listW,vulnerable.eku$Vulnerability)
#summary(lA)
moran.test(vulnerable.eku$Vulnerability,listW)
geary.test(vulnerable.eku$Vulnerability,listW)
#definitely spatial correlation in vul.

vul_and_sev.eku <- vulnerable.eku
vul_and_sev.eku@data <- cbind(vulnerable.eku@data,sev.eku$critical)
moran.test(vul_and_sev.eku$critical,listW)
geary.test(vul_and_sev.eku$critical,listW)

#for cases and waste water tests, see below INLA setup
```

### Setup for INLA
```{r}
#random effect IDs
data.final <- cbind(data.final,u = rep(1:112,28))
data.final <- cbind(data.final,v = rep(1:112,28))
data.final <- cbind(data.final,time = rep(1:28,rep(112,28)))

# Spatial neighbourhood for BYM model
SHP.ek2 <- SHP.ek
SHP.ek2@data <- data.final
data.final <- SHP.ek2
data.final@data$Cases <- round(data.final@data$Cases) #due to poisson likelihood (discrete)
nb2INLA("final.adj",poly2nb(data.final))
spatial.comp <- inla.read.graph(filename = "final.adj")
```

### Autocorrelation continued
```{r}
moran.mc(data.final@data$Cases[3025:3136],listw = nb2listw(poly2nb(data.final))
           ,alternative = "two.sided",nsim = 10000)

moran.mc(data.final@data$N1_cusum[3025:3136],listw = nb2listw(poly2nb(data.final))
           ,alternative = "two.sided",nsim = 10000)

#test for residual autocorrelation
ns.mod <- glm(Cases~log(N1_cusum+1)+Vulnerability+Severity+Movement+time+u,data = data.final@data,family="poisson")
#checking actual case numbers and fitted values these residuals are wrong:
#need to check, something isnt right

plot((data.final@data$Cases - ns.mod$fitted.values))

ns.resid <- data.final@data$Cases - ns.mod$fitted.values
moran.mc(ns.resid[(10*112+1):(112*11)],nb2listw(poly2nb(data.final),style="W"),nsim=10000,alternative = "two.sided")
moran.mc(ns.resid[(27*112+1):(112*28)],nb2listw(poly2nb(data.final),style="W"),nsim=10000,alternative = "two.sided")
#issue with expected value and lm.morantest() not compatible
```

### Scalings for measurement error
```{r}
#exponential distance
scales <- vector(length=112,mode="numeric")
for(i in 1:112) {
  if(i %in% indD) {
    scales[i] <- exp(-alpha[9]*distances[i,67])
  }
  
  if(i %in% indHBCG) {
    scales[i] <- exp(-alpha[9]*distances[i,88])
  }
  
  if(i %in% indJP) {
    scales[i] <- exp(-alpha[9]*distances[i,73])
  }
  
  if(i %in% indJS) {
    scales[i] <- exp(-alpha[9]*distances[i,97])
  }
  
  if(i %in% indO) {
    scales[i] <- exp(-alpha[9]*distances[i,89])
  }
  
  if(i %in% indR) {
    scales[i] <- exp(-alpha[9]*distances[i,27])
  }
  
  if(i %in% indV) {
    scales[i] <- exp(-alpha[9]*distances[i,107])
  }
}


for(i in 1:112) {
  
  if(i %in% r1) {
    scales[i] <- 10/11*mean(scales[n1])
  }
  
  if(i %in% r2) {
    scales[i] <- 10/11*mean(scales[n2])
  }
  
  if(i %in% r3) {
    scales[i] <- 10/11*mean(scales[n3])
  }
  
  if(i %in% r4) {
    scales[i] <- 10/11*mean(scales[n4])
  }
}

scales <- c(rep(c(scales,0.9*scales),5),rep(scales,5),0.9*scales,rep(scales,12))
#extra uncertainty for time interpolating

#2021-09-28 2021-10-12 2021-10-26 2021-11-09 2021-11-23 2022-01-04




test.model.exp <- inla(Cases~ f(logN1,model="meb",scale = scales,values=logN1) +
                     f(time,model="rw1",scale.model = TRUE,
                       hyper = list(theta = list(prior="pc.prec", param=c(1,0.01))))+
                     f(u,model="besag",graph=spatial.comp,scale.model = TRUE)+
                     f(v,model="iid"), family = "poisson",
                   data = data.temp@data, control.compute = list(dic=TRUE,cpo=TRUE,po=TRUE),
                   control.predictor = list(link=1))

#inverse distance
scales <- vector(length=112,mode="numeric")
for(i in 1:112) {
  if(i %in% indD) {
    scales[i] <- (1/distances[i,67])^alpha[22]
  }
  
  if(i %in% indHBCG) {
    scales[i] <- (1/distances[i,88])^alpha[22]
  }
  
  if(i %in% indJP) {
    scales[i] <- (1/distances[i,73])^alpha[22]
  }
  
  if(i %in% indJS) {
    scales[i] <-(1/distances[i,97])^alpha[22]
  }
  
  if(i %in% indO) {
    scales[i] <- (1/distances[i,89])^alpha[22]
  }
  
  if(i %in% indR) {
    scales[i] <- (1/distances[i,27])^alpha[22]
  }
  
  if(i %in% indV) {
    scales[i] <- (1/distances[i,107])^alpha[22]
  }
}

scales[is.infinite(scales)] <- max(1,scales[is.finite(scales)])

for(i in 1:112) {
  
  if(i %in% r1) {
    scales[i] <- 10/11*mean(scales[n1])
  }
  
  if(i %in% r2) {
    scales[i] <- 10/11*mean(scales[n2])
  }
  
  if(i %in% r3) {
    scales[i] <- 10/11*mean(scales[n3])
  }
  
  if(i %in% r4) {
    scales[i] <- 10/11*mean(scales[n4])
  }
}

scales <- c(rep(c(scales,0.9*scales),5),rep(scales,5),0.9*scales,rep(scales,12))

test.model.idw <- inla(Cases~ f(logN1,model="meb",scale = scales,values=logN1) +
                     f(time,model="rw1",scale.model = TRUE,
                       hyper = list(theta = list(prior="pc.prec", param=c(1,0.01))))+
                     f(u,model="besag",graph=spatial.comp,scale.model = TRUE)+
                     f(v,model="iid"), family = "poisson",
                   data = data.fit@data, control.compute = list(dic=TRUE,cpo=TRUE,po=TRUE),
                   control.predictor = list(link=1))
```

### Final model fits
```{r}
data.fit <- data.final
data.fit@data$Cases <- c(data.final@data$Cases[1:3024],rep(NA,112))
data.fit@data <- cbind(data.final@data,logN1 = log(data.final@data$N1_cusum+1) + rnorm(3136,0.005,0.0001))
data.fit@data <- cbind(data.fit@data,time2=data.final@data$time)
data.fit@data <- cbind(data.fit@data,ID=1:3136)
data.fit@data$Cases <- c(data.final@data$Cases[1:3024],rep(NA,112))

inla.ar1 <- inla(Cases~logN1+Severity+Movement+Vulnerability+
                   f(time,model="ar1")+
                   f(WardNumber,model="bym",graph = spatial.comp)+
                   f(time2,model="iid"),data=data.fit@data,family="poisson",
                   control.compute = list(dic=TRUE,cpo=TRUE,po=TRUE),
                   control.predictor = list(link=1))

spatial.model.rw1 <-  inla(Cases~logN1+
                            f(u,model="bym",graph=spatial.comp,scale.model = TRUE)+
                            f(time,model="rw1"), family = "poisson",
                          data = data.fit@data, control.compute = list(dic=TRUE,cpo=TRUE,po=TRUE),
                          control.predictor = list(compute=TRUE))

inla.rw1 <- inla(Cases~logN1+
                    f(time,model="rw1",scale.model = TRUE,
                       hyper = list(theta = list(prior="pc.prec", param=c(1,0.01))))+
                     f(u,model="bym",graph=spatial.comp,scale.model = TRUE)+
                     f(time2,model="iid"), family = "poisson",
                   data = data.fit@data, control.compute = list(dic=TRUE,cpo=TRUE,po=TRUE),
                   control.predictor = list(link=1))

#random effects not have some negative slopes
inla.z <- inla(Cases~log(N1_cusum+1)+f(ID,model="z",Z=Z.mat)+
             +f(time,model="rw1",scale.model = TRUE,
                       hyper = list(theta = list(prior="pc.prec", param=c(1,0.01))))+
             f(WardNumber,model="bym",graph = spatial.comp,scale.model = TRUE), family = "poisson",
             data = data.fit@data, control.compute = list(dic=TRUE,cpo=TRUE,po=TRUE),
            control.predictor = list(compute=TRUE))
#idw is best
inla.meb <- inla(Cases~ f(logN1,model="meb",scale = scales,values=logN1) +
                     f(time,model="rw1",scale.model = TRUE,
                       hyper = list(theta = list(prior="pc.prec", param=c(1,0.01))))+
                     f(WardNumber,model="bym",graph=spatial.comp)+
                     f(time2,model="iid"), family = "poisson",
                   data = data.fit@data, control.compute = list(dic=TRUE,cpo=TRUE,po=TRUE),
                   control.predictor = list(link=1))

inla.meb2 <- inla(Cases~ f(logN1,model="meb",scale = scales,values=logN1) +
                     f(time,model="rw1",scale.model = TRUE,
                       hyper = list(theta = list(prior="pc.prec", param=c(1,0.01))))+
                     f(WardNumber,model="bym",graph=spatial.comp)+
                     f(time2,model="iid")+f(time.ward,model="iid"), family = "poisson",
                   data = data.fit@data, control.compute = list(dic=TRUE,cpo=TRUE,po=TRUE),
                   control.predictor = list(link=1))

data.fit@data <- cbind(data.fit@data,time.ward = 1:3136)
#interaction
inla.int <- inla(Cases~logN1+
                    f(time,model="rw1",scale.model = TRUE,
                       hyper = list(theta = list(prior="pc.prec", param=c(1,0.01))))+
                     f(u,model="bym",graph=spatial.comp,scale.model = TRUE)+
                     f(time2,model="iid")+f(time.ward,model="iid"), family = "poisson",
                   data = data.fit@data, control.compute = list(dic=TRUE,cpo=TRUE,po=TRUE),
                   control.predictor = list(link=1))

#example of PMCC calculation
sum((data.final@data$Cases-exp(inla.int$summary.linear.predictor[,1]))^2)+sum((exp(inla.int$summary.linear.predictor[,5])-exp(inla.int$summary.linear.predictor[,3]))/2)
```




### MCMC
Try carBayesST package:
prediction ability is not good
```{r}
#library(CARBayesST)
#need to check convergence, but already slow, so more sims not possible
model.cbst <- ST.CARanova(Cases~log(N1_cusum+1),data = data.temp@data,W = nb2mat(poly2nb(data.final),style="B")
                          ,family = "poisson",burnin = 10000,n.sample = 50000,thin = 4 )
#actually looks good
model.cbst <- ST.CARsepspatial(Cases~log(N1_cusum+1),
                               data =data.final@data,W=nb2mat(poly2nb(data.final),style="B")
                          ,family = "poisson",burnin = 10000,n.sample = 50000)
#not possible to predict in package yet (may be overfitting)
model.cbst <- ST.CARsepspatial(Cases~log(N1_cusum+1),
                               data =data.temp@data,W=nb2mat(poly2nb(data.final),style="B")
                          ,family = "poisson",burnin = 10000,n.sample = 50000)

model.cbst <- ST.CARar(Cases~log(N1_cusum+1),
                               data =data.temp@data,W=nb2mat(poly2nb(data.final),style="B")
                          ,family = "poisson",burnin = 50000,n.sample = 100000,AR = 1)

model.cbst <- ST.CARlinear(Cases~log(N1_cusum+1),
                               data =data.temp@data,W=nb2mat(poly2nb(data.final),style="B")
                          ,family = "poisson",burnin = 50000,n.sample = 100000)

```

